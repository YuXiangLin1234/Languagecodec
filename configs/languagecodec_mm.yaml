seed_everything: 4444

data:
  class_path: languagecodec_decoder.dataset.VocosDataModule
  init_args:
    train_params:
      filelist_path: /home/yxlin/backup/cv-corpus-18.0-2024-06-14/zh-TW/my_train.txt
      sampling_rate: 24000
      num_samples: 24000
      batch_size: 16
      num_workers: 8

    val_params:
      filelist_path: /home/yxlin/backup/cv-corpus-18.0-2024-06-14/zh-TW/my_test.txt
      sampling_rate: 24000
      num_samples: 24000
      batch_size: 8
      num_workers: 8

model:
  class_path: languagecodec_decoder.experiment.VocosEncodecExp
  init_args:
    sample_rate: 24000
    initial_learning_rate: 1e-5
    mel_loss_coeff: 45
    mrd_loss_coeff: 1.0
    num_warmup_steps: 0 # Optimizers warmup steps
    pretrain_mel_steps: 0  # 0 means GAN objective from the first iteration

    # automatic evaluation
    evaluate_utmos: true
    evaluate_pesq: true
    evaluate_periodicty: true

    resume: true
    resume_config: /home/yxlin/Languagecodec/configs/languagecodec_mm.yaml
    resume_model: /home/yxlin/Languagecodec/pretrained_models/languagecodec_paper.ckpt

    feature_extractor:
      class_path: languagecodec_decoder.feature_extractors.EncodecFeatures
      init_args:
        encodec_model: encodec_24khz
        bandwidths: [6.6, 6.6, 6.6, 6.6]
        train_codebooks: false

    backbone:
      class_path: languagecodec_decoder.models.VocosBackbone
      init_args:
        input_channels: 128
        dim: 384
        intermediate_dim: 1152
        num_layers: 12
        adanorm_num_embeddings: 4  # len(bandwidths)

    head:
      class_path: languagecodec_decoder.heads.ISTFTHead
      init_args:
        dim: 384
        n_fft: 1280
        hop_length: 320
        padding: same
# https://github.com/Lightning-AI/pytorch-lightning/pull/4376/files
trainer:
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      save_dir: /home/yxlin/Languagecodec/results
  callbacks:
    class_path: 'pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step'
    class_path: 'pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2'
    class_path: 'pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        filename: vocos_checkpoint_{epoch}_{step}_{val_loss:.4f}
        save_top_k: 50
        save_last: true'
    class_path: languagecodec_decoder.helpers.GradNormCallback

  # Lightning calculates max_steps across all optimizer steps (rather than number of batches)
  # This equals to 1M steps per generator and 1M per discriminator
  # max_steps: 20000000
  max_steps: 10000
  # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  limit_val_batches: 100
  accelerator: gpu
  strategy: ddp
  devices: [0]
  log_every_n_steps: 50
